import os
import pandas as pd

# ========= USER INPUTS =========
SOURCE_FILE = r"C:\Users\Sourav.Sindhikar\Downloads\Mapping\Output 2 - Usermapping\With Parent\UserMapping-Alliance_Parent_V1.csv"
LOOKUP_FILE = r"C:\Users\Sourav.Sindhikar\Downloads\Mapping\Case_alliance_accountLKP.xlsx"
OUTPUT_DIR = r"C:\Users\Sourav.Sindhikar\Downloads\Mapping\Acount_mapping"
OUTPUT_FILE = os.path.join(OUTPUT_DIR, "accountid_mapped.csv")
UNMATCHED_FILE = os.path.join(OUTPUT_DIR, "no_match_accountid.csv")
# Column names
SOURCE_ID_COL = "AccountId"
RECORDTYPE_COL = "Account.Recordtype.Name"
BUSINESS_HOURS_COL = "BusinessHoursId"
LOOKUP_KEY_COL = "Legacy_SF_Record_ID__c"
LOOKUP_VALUE_COL = "Id"
# ========= CONSTANTS =========
ARROW_VERTICAL_ACCOUNT_ID = "001Wr00000mKja2IAC"
UNITY_ACCOUNT_ID = "001Wr00000mKWszIAG"
BUSINESS_HOURS_ID = "01mWr0000012RrmIAE"
CHUNK_SIZE = 50_000
# ========= END OF USER INPUTS =========


def load_lookup(path, key_col, value_col):
    if not os.path.exists(path):
        raise FileNotFoundError(f"Lookup file not found: {path}")

    if path.lower().endswith((".xls", ".xlsx")):
        lookup_df = pd.read_excel(path, dtype=str)
    else:
        lookup_df = pd.read_csv(path, dtype=str)

    lookup_df = lookup_df.fillna("")
    missing = {key_col, value_col} - set(lookup_df.columns)
    if missing:
        raise ValueError(f"Missing column(s) in lookup file: {', '.join(missing)}")

    for col in lookup_df.columns:
        lookup_df[col] = lookup_df[col].astype(str).str.strip()

    return {
        str(k).strip().lower(): str(v).strip()
        for k, v in zip(lookup_df[key_col], lookup_df[value_col])
        if str(k).strip()
    }


def map_account_id(raw_value, lookup_dict):
    raw_value = (raw_value or "").strip()
    if not raw_value:
        return ""
    return lookup_dict.get(raw_value.lower(), "")


def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    for path in (OUTPUT_FILE, UNMATCHED_FILE):
        if os.path.exists(path):
            os.remove(path)
            print(f"âš ï¸ Removed existing file: {path}")

    if not os.path.exists(SOURCE_FILE):
        raise FileNotFoundError(f"Source file not found: {SOURCE_FILE}")

    print("ğŸ“– Loading lookup file...")
    dict_lookup = load_lookup(LOOKUP_FILE, LOOKUP_KEY_COL, LOOKUP_VALUE_COL)

    reader = pd.read_csv(SOURCE_FILE, dtype=str, chunksize=CHUNK_SIZE)
    header_written_mapped = False
    header_written_unmatched = False
    total_rows = mapped_count = unmatched_count = 0

    print("ğŸ”„ Processing source file in chunks...")
    for i, chunk in enumerate(reader, start=1):
        chunk = chunk.fillna("")

        if SOURCE_ID_COL not in chunk.columns:
            print(f"âš ï¸ Column '{SOURCE_ID_COL}' missing in chunk {i}, skipping...")
            continue

        original_account_ids = chunk[SOURCE_ID_COL].copy()

        # Step 1: Map AccountId using lookup
        chunk[SOURCE_ID_COL] = chunk[SOURCE_ID_COL].apply(
            lambda val: map_account_id(val, dict_lookup)
        )

        # Step 2: Override AccountId based on RecordType
        if RECORDTYPE_COL in chunk.columns:
            recordtype_values = chunk[RECORDTYPE_COL].astype(str).str.strip()
            
            # "Arrow / Verical" â†’ set to ARROW_VERTICAL_ACCOUNT_ID
            arrow_vertical_mask = recordtype_values == "Arrow / Verical"
            chunk.loc[arrow_vertical_mask, SOURCE_ID_COL] = ARROW_VERTICAL_ACCOUNT_ID
            
            # "Unity" â†’ set to UNITY_ACCOUNT_ID
            unity_mask = recordtype_values == "Unity"
            chunk.loc[unity_mask, SOURCE_ID_COL] = UNITY_ACCOUNT_ID

        # Step 3: Set BusinessHoursId for all rows
        if BUSINESS_HOURS_COL in chunk.columns:
            chunk[BUSINESS_HOURS_COL] = BUSINESS_HOURS_ID
        else:
            chunk[BUSINESS_HOURS_COL] = BUSINESS_HOURS_ID

        # Determine matched vs unmatched
        original_stripped = original_account_ids.astype(str).str.strip()
        mapped_stripped = chunk[SOURCE_ID_COL].astype(str).str.strip()

        # Mapped output: includes matched rows AND originally blank rows
        mapped_output_mask = (mapped_stripped != "") | (original_stripped == "")
        
        # Unmatched: only rows where original had value but mapping failed (before RecordType override)
        # Check if original lookup failed (not overridden by RecordType)
        temp_mapped = original_account_ids.apply(
            lambda val: map_account_id(val, dict_lookup)
        )
        temp_mapped_stripped = temp_mapped.astype(str).str.strip()
        unmatched_mask = (original_stripped != "") & (temp_mapped_stripped == "")
        
        # Exclude rows that were overridden by RecordType from unmatched
        if RECORDTYPE_COL in chunk.columns:
            recordtype_values = chunk[RECORDTYPE_COL].astype(str).str.strip()
            recordtype_override_mask = recordtype_values.isin(["Arrow / Verical", "Unity"])
            unmatched_mask = unmatched_mask & ~recordtype_override_mask

        mapped_chunk = chunk[mapped_output_mask].copy()
        unmatched_chunk = chunk[unmatched_mask].copy()

        # For unmatched file: restore original AccountId but keep all other updates (BusinessHoursId, etc.)
        if len(unmatched_chunk) > 0:
            unmatched_chunk = unmatched_chunk.reset_index(drop=True)
            original_unmatched = original_account_ids[unmatched_mask].reset_index(drop=True)
            unmatched_chunk[SOURCE_ID_COL] = original_unmatched

        # Write mapped output (includes matched + blanks)
        if len(mapped_chunk) > 0:
            mapped_chunk.to_csv(
                OUTPUT_FILE,
                index=False,
                mode="a" if header_written_mapped else "w",
                header=not header_written_mapped,
                encoding="utf-8-sig",
            )
            header_written_mapped = True
            mapped_count += len(mapped_chunk)

        # Write unmatched file (only non-blank source values that failed to map)
        if len(unmatched_chunk) > 0:
            unmatched_chunk.to_csv(
                UNMATCHED_FILE,
                index=False,
                mode="a" if header_written_unmatched else "w",
                header=not header_written_unmatched,
                encoding="utf-8-sig",
            )
            header_written_unmatched = True
            unmatched_count += len(unmatched_chunk)

        total_rows += len(chunk)
        print(
            f"âœ… Chunk {i}: {len(chunk)} rows | Mapped output: {len(mapped_chunk)} | Unmatched: {len(unmatched_chunk)}"
        )

    print("\nâœ… Mapping completed!")
    print(f"ğŸ“Š Total rows processed: {total_rows}")
    print(f"âœ… Mapped output rows (matched + blanks): {mapped_count} â†’ {OUTPUT_FILE}")
    print(f"âš ï¸ Unmatched rows: {unmatched_count} â†’ {UNMATCHED_FILE}")


if __name__ == "__main__":
    main()
